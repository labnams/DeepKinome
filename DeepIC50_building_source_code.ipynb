{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "\n",
    "import statistics\n",
    "import random\n",
    "from scipy import stats\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv1D, MaxPooling1D, AveragePooling, Input, Reshape, BatchNormalization, Concatenate\n",
    "\n",
    "os.getcwd()\n",
    "workdir = \"your working directory\"\n",
    "datadir = workdir + \"KinomeScan_data/\"\n",
    "resultdir = datadir + \"input_result/\"\n",
    "predictiondir = datadir + \"prediction_result/\"\n",
    "modeldir = workdir + \"model/\"\n",
    "\n",
    "today = datetime.today().strftime(\"%Y%m%d\")\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load whole dataset from npz\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    train_data = np.load(resultdir + 'toy_train.npz')\n",
    "    val_data = np.load(resultdir + 'toy_val.npz')\n",
    "    test_data = np.load(resultdir + 'toy_test.npz')\n",
    "    train_data.files, val_data.files, test_data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_data['x'], train_data['y']\n",
    "x_val, y_val = val_data['x'], val_data['y']\n",
    "x_test, y_test = test_data['x'], test_data['y']\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "LR = 0.000001\n",
    "training_epochs = 200\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred -y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "## for yoon # Input size should be [batch, 1d, 2d, ch] = (None, 1, 15000, 1)\n",
    "    model.add(Conv1D (kernel_size = 11, filters = 16, input_shape=(x_train.shape[1],x_train.shape[2]), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size = 11, filters = 16, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2, strides = 2, padding='same'))\n",
    "    model.add(Conv1D (kernel_size = 11, filters = 32, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size = 11, filters = 32, padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size = 2, strides = 2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size = 11, filters = 64, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2, strides = 2, padding='same'))\n",
    "    model.add(Conv1D (kernel_size = 11, filters = 64, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 2, strides = 2, padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense (1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense (2048))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense (4096))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense (2048))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense (1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    # model.add(Dense(num_classes, activation = 'softmax',activity_regularizer=keras.regularizers.l2()  ))\n",
    "    model.add(Dense(1, activation = 'linear', activity_regularizer= tf.keras.regularizers.L2()  ))\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=LR), loss = rmse, metrics =[\"mse\"])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = model.fit(x_train, y_train, batch_size=32,epochs=100,verbose=1,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RMSE plot\n",
    "plt.figure()\n",
    "plt.title(\"RMSE\")\n",
    "plt.plot(model_train.history['loss'],\"r\", label = \"Tranning\")\n",
    "plt.plot(model_train.history['val_loss'], label = \"Validation\", color = 'dodgerblue')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend(loc=2)\n",
    "# plt.savefig(model_name+\"_\"+timetail+\"_rmse.png\")\n",
    "\n",
    "#Using when system memory is insufficient\n",
    "#train_X=[]\n",
    "#tval_X=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "test_r2 = r2_score(y_test, pred_test)\n",
    "print(\"test RMSE : \", test_rmse)\n",
    "print(\"test R2 : \", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw scatter plot\n",
    "plt.xlabel(\"Original\",size = 20)\n",
    "plt.ylabel(\"Predictions\",size = 20)\n",
    "plt.scatter(y_test, pred_test, s=5)\n",
    "ident = [y_test.min(),y_test.max()]\n",
    "plt.plot(ident,ident,'--', color='black',linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Save/Load the Entire Model\n",
    "from keras.models import load_model\n",
    "\n",
    "# Creates a HDF5 file 'my_model.h5'\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
